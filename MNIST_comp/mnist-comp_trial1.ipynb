{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-19T16:55:55.196259Z","iopub.execute_input":"2025-02-19T16:55:55.196572Z","iopub.status.idle":"2025-02-19T16:55:56.505746Z","shell.execute_reply.started":"2025-02-19T16:55:55.196532Z","shell.execute_reply":"2025-02-19T16:55:56.504567Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split, KFold\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\n\ntrain = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T17:01:47.876628Z","iopub.execute_input":"2025-02-19T17:01:47.877026Z","iopub.status.idle":"2025-02-19T17:01:51.594925Z","shell.execute_reply.started":"2025-02-19T17:01:47.876996Z","shell.execute_reply":"2025-02-19T17:01:51.593920Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"test=test/255\ny_train = train[\"label\"]  # Copy labels\ny_train= to_categorical(y_train, num_classes = 10) # One-hot encode the labels\ntrain = train.drop(columns=[\"label\"]) / 255  # Normalize without modifying the original\ntrain_xCNN=train.to_numpy().reshape(-1, 28, 28, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T17:02:00.177449Z","iopub.execute_input":"2025-02-19T17:02:00.177833Z","iopub.status.idle":"2025-02-19T17:02:00.429693Z","shell.execute_reply.started":"2025-02-19T17:02:00.177802Z","shell.execute_reply":"2025-02-19T17:02:00.428519Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model_CNN = keras.Sequential([\n    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPooling2D((2,2)),\n    \n    keras.layers.Conv2D(64, (3,3), activation='relu'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(64, (3,3), strides=2, padding='same', activation='relu'),  # Strided convolution instead of pooling\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.4),  # Regularization\n    \n    keras.layers.Flatten(),\n    keras.layers.Dense(128),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation('relu'),\n    keras.layers.Dropout(0.4),  # Regularization\n    keras.layers.Dense(10, activation='softmax')  # 10 output classes\n])\n\nmodel_CNN.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Summary\nmodel_CNN.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T17:02:03.612374Z","iopub.execute_input":"2025-02-19T17:02:03.612739Z","iopub.status.idle":"2025-02-19T17:02:03.848557Z","shell.execute_reply.started":"2025-02-19T17:02:03.612692Z","shell.execute_reply":"2025-02-19T17:02:03.846895Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m36,928\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m295,040\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m353,226\u001b[0m (1.35 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353,226</span> (1.35 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m352,650\u001b[0m (1.35 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352,650</span> (1.35 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m576\u001b[0m (2.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> (2.25 KB)\n</pre>\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        rotation_range=10,  \n        zoom_range = 0.10,  \n        width_shift_range=0.1, \n        height_shift_range=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T17:02:28.853909Z","iopub.execute_input":"2025-02-19T17:02:28.854267Z","iopub.status.idle":"2025-02-19T17:02:28.858904Z","shell.execute_reply.started":"2025-02-19T17:02:28.854238Z","shell.execute_reply":"2025-02-19T17:02:28.857930Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"epochs = 45\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.98 ** x)\n\n# Train-test split\nX_train2, X_val2, Y_train2, Y_val2 = train_test_split(train_xCNN, y_train, test_size=0.1)  # FIXED\n\n# Train model\nhistory = model_CNN.fit(datagen.flow(X_train2, Y_train2, batch_size=64),  # FIXED\n                        epochs=epochs,\n                        steps_per_epoch=len(X_train2) // 64,\n                        validation_data=(X_val2, Y_val2),\n                        callbacks=[annealer],\n                        verbose=1)\n\n# Evaluate model\nval_loss, val_acc = model_CNN.evaluate(X_val2, Y_val2)\nprint(f\"Validation Accuracy: {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T17:02:34.866967Z","iopub.execute_input":"2025-02-19T17:02:34.867303Z","iopub.status.idle":"2025-02-19T17:16:39.688161Z","shell.execute_reply.started":"2025-02-19T17:02:34.867276Z","shell.execute_reply":"2025-02-19T17:16:39.687112Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/45\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 61ms/step - accuracy: 0.7777 - loss: 0.7018 - val_accuracy: 0.9731 - val_loss: 0.1131 - learning_rate: 0.0010\nEpoch 2/45\n\u001b[1m  1/590\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 45ms/step - accuracy: 0.9062 - loss: 0.2103","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2103 - val_accuracy: 0.9707 - val_loss: 0.1198 - learning_rate: 9.8000e-04\nEpoch 3/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 61ms/step - accuracy: 0.9587 - loss: 0.1423 - val_accuracy: 0.9793 - val_loss: 0.0694 - learning_rate: 9.6040e-04\nEpoch 4/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1114 - val_accuracy: 0.9798 - val_loss: 0.0671 - learning_rate: 9.4119e-04\nEpoch 5/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 59ms/step - accuracy: 0.9663 - loss: 0.1114 - val_accuracy: 0.9838 - val_loss: 0.0550 - learning_rate: 9.2237e-04\nEpoch 6/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1820 - val_accuracy: 0.9857 - val_loss: 0.0504 - learning_rate: 9.0392e-04\nEpoch 7/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 61ms/step - accuracy: 0.9732 - loss: 0.0875 - val_accuracy: 0.9862 - val_loss: 0.0434 - learning_rate: 8.8584e-04\nEpoch 8/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0342 - val_accuracy: 0.9864 - val_loss: 0.0431 - learning_rate: 8.6813e-04\nEpoch 9/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 59ms/step - accuracy: 0.9768 - loss: 0.0792 - val_accuracy: 0.9898 - val_loss: 0.0299 - learning_rate: 8.5076e-04\nEpoch 10/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0265 - val_accuracy: 0.9895 - val_loss: 0.0306 - learning_rate: 8.3375e-04\nEpoch 11/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 59ms/step - accuracy: 0.9789 - loss: 0.0705 - val_accuracy: 0.9857 - val_loss: 0.0414 - learning_rate: 8.1707e-04\nEpoch 12/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.2386 - val_accuracy: 0.9850 - val_loss: 0.0415 - learning_rate: 8.0073e-04\nEpoch 13/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 59ms/step - accuracy: 0.9801 - loss: 0.0644 - val_accuracy: 0.9900 - val_loss: 0.0324 - learning_rate: 7.8472e-04\nEpoch 14/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0412 - val_accuracy: 0.9895 - val_loss: 0.0325 - learning_rate: 7.6902e-04\nEpoch 15/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 60ms/step - accuracy: 0.9818 - loss: 0.0639 - val_accuracy: 0.9886 - val_loss: 0.0379 - learning_rate: 7.5364e-04\nEpoch 16/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0321 - val_accuracy: 0.9886 - val_loss: 0.0379 - learning_rate: 7.3857e-04\nEpoch 17/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 59ms/step - accuracy: 0.9815 - loss: 0.0576 - val_accuracy: 0.9860 - val_loss: 0.0414 - learning_rate: 7.2380e-04\nEpoch 18/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9857 - val_loss: 0.0419 - learning_rate: 7.0932e-04\nEpoch 19/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 58ms/step - accuracy: 0.9858 - loss: 0.0487 - val_accuracy: 0.9910 - val_loss: 0.0273 - learning_rate: 6.4117e-04\nEpoch 24/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0792 - val_accuracy: 0.9905 - val_loss: 0.0276 - learning_rate: 6.2835e-04\nEpoch 25/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 58ms/step - accuracy: 0.9855 - loss: 0.0459 - val_accuracy: 0.9912 - val_loss: 0.0229 - learning_rate: 6.1578e-04\nEpoch 26/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0345 - val_accuracy: 0.9912 - val_loss: 0.0230 - learning_rate: 6.0346e-04\nEpoch 27/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 59ms/step - accuracy: 0.9865 - loss: 0.0433 - val_accuracy: 0.9914 - val_loss: 0.0266 - learning_rate: 5.9140e-04\nEpoch 28/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.2162 - val_accuracy: 0.9914 - val_loss: 0.0269 - learning_rate: 5.7957e-04\nEpoch 29/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 58ms/step - accuracy: 0.9850 - loss: 0.0474 - val_accuracy: 0.9936 - val_loss: 0.0198 - learning_rate: 5.6798e-04\nEpoch 30/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.1267 - val_accuracy: 0.9936 - val_loss: 0.0197 - learning_rate: 5.5662e-04\nEpoch 31/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 58ms/step - accuracy: 0.9872 - loss: 0.0428 - val_accuracy: 0.9926 - val_loss: 0.0247 - learning_rate: 5.4548e-04\nEpoch 32/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0738 - val_accuracy: 0.9926 - val_loss: 0.0246 - learning_rate: 5.3457e-04\nEpoch 33/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 59ms/step - accuracy: 0.9865 - loss: 0.0446 - val_accuracy: 0.9902 - val_loss: 0.0296 - learning_rate: 5.2388e-04\nEpoch 34/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9907 - val_loss: 0.0292 - learning_rate: 5.1341e-04\nEpoch 35/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 58ms/step - accuracy: 0.9881 - loss: 0.0384 - val_accuracy: 0.9931 - val_loss: 0.0184 - learning_rate: 5.0314e-04\nEpoch 36/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9933 - val_loss: 0.0185 - learning_rate: 4.9307e-04\nEpoch 37/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 58ms/step - accuracy: 0.9878 - loss: 0.0403 - val_accuracy: 0.9907 - val_loss: 0.0265 - learning_rate: 4.8321e-04\nEpoch 38/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0348 - val_accuracy: 0.9907 - val_loss: 0.0262 - learning_rate: 4.7355e-04\nEpoch 39/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 58ms/step - accuracy: 0.9888 - loss: 0.0385 - val_accuracy: 0.9924 - val_loss: 0.0229 - learning_rate: 4.6408e-04\nEpoch 40/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.0782 - val_accuracy: 0.9924 - val_loss: 0.0229 - learning_rate: 4.5480e-04\nEpoch 41/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 59ms/step - accuracy: 0.9890 - loss: 0.0345 - val_accuracy: 0.9900 - val_loss: 0.0289 - learning_rate: 4.4570e-04\nEpoch 42/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.1624 - val_accuracy: 0.9898 - val_loss: 0.0285 - learning_rate: 4.3679e-04\nEpoch 43/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 59ms/step - accuracy: 0.9903 - loss: 0.0319 - val_accuracy: 0.9921 - val_loss: 0.0228 - learning_rate: 4.2805e-04\nEpoch 44/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0170 - val_accuracy: 0.9914 - val_loss: 0.0229 - learning_rate: 4.1949e-04\nEpoch 45/45\n\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 58ms/step - accuracy: 0.9910 - loss: 0.0298 - val_accuracy: 0.9924 - val_loss: 0.0233 - learning_rate: 4.1110e-04\n\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0266\nValidation Accuracy: 0.9924\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model_CNN.save('trained_model.h5')\ntest_xCNN=test.to_numpy().reshape(-1, 28, 28, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T17:16:57.087705Z","iopub.execute_input":"2025-02-19T17:16:57.088174Z","iopub.status.idle":"2025-02-19T17:16:57.164313Z","shell.execute_reply.started":"2025-02-19T17:16:57.088137Z","shell.execute_reply":"2025-02-19T17:16:57.163236Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\npredictions = model_CNN.predict(test_xCNN)\npredicted_labels = np.argmax(predictions, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T17:30:05.839696Z","iopub.execute_input":"2025-02-19T17:30:05.840101Z","iopub.status.idle":"2025-02-19T17:30:13.373010Z","shell.execute_reply.started":"2025-02-19T17:30:05.840071Z","shell.execute_reply":"2025-02-19T17:30:13.371664Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Create a DataFrame with ImageId and Prediction\nsubmission = pd.DataFrame({\n    \"ImageId\": np.arange(1, len(predicted_labels) + 1),  # Image IDs start from 1\n    \"Label\": predicted_labels\n})\n\n# Save to CSV\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"CSV file 'submission.csv' saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T17:31:09.400039Z","iopub.execute_input":"2025-02-19T17:31:09.400375Z","iopub.status.idle":"2025-02-19T17:31:09.435220Z","shell.execute_reply.started":"2025-02-19T17:31:09.400349Z","shell.execute_reply":"2025-02-19T17:31:09.434052Z"}},"outputs":[{"name":"stdout","text":"CSV file 'submission.csv' saved successfully!\n","output_type":"stream"}],"execution_count":18}]}